{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EduSpend CP#30: Global Higher-Education Cost Analytics & Planning\n",
    "Model Comparison Provided by Cursor\n",
    "\n",
    "This code compares the performance of different models (Linear Reg, Random Forest, SVR, LightGBM, XGBoost)  \n",
    "on a dataset related to global higher-education costs, using Mean Squared Error and R^2 Score.  \n",
    "The dataset is assumed to be preprocessed and available as 'edu_cost_data'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset, Total Cost of Attendance\n",
    "edu_cost_data = pd.read_csv('../data/TCA_no_outliers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target variable\n",
    "X = edu_cost_data.drop('TCA', axis=1)\n",
    "y = edu_cost_data['TCA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Feature Engineering: Low, Medium, High TCA*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TCA tiers based on training data quantiles\n",
    "tca_quantiles = y_train.quantile([0.33, 0.67])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCA Tier Boundaries (based on training data):\n",
      "Low, 33rd percentile: < $27,008\n",
      "Medium, 33rd - 67th percentile: $27,008 - $62,960\n",
      "High, 67th percentile: > $62,960\n"
     ]
    }
   ],
   "source": [
    "# Define tier boundaries based on training data quantiles\n",
    "train_tca_tiers = pd.cut(y_train, bins=[0, tca_quantiles[0.33], tca_quantiles[0.67], float('inf')],\n",
    "                     labels=['Low', 'Medium', 'High'])\n",
    "test_tca_tiers = pd.cut(y_test, bins=[0, tca_quantiles[0.33], tca_quantiles[0.67], float('inf')],\n",
    "                    labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "print(f\"TCA Tier Boundaries (based on training data):\")\n",
    "print(f\"Low, 33rd percentile: < ${tca_quantiles[0.33]:,.0f}\")\n",
    "print(f\"Medium, 33rd - 67th percentile: ${tca_quantiles[0.33]:,.0f} - ${tca_quantiles[0.67]:,.0f}\")\n",
    "print(f\"High, 67th percentile: > ${tca_quantiles[0.67]:,.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add tiers to your feature sets\n",
    "X_train['TCA_Tier'] = train_tca_tiers\n",
    "X_test['TCA_Tier'] = test_tca_tiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Encoding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TCA tiers to numerical order\n",
    "# Define categories in the correct order: 0, 1, 2\n",
    "categories = [['Low', 'Medium', 'High']]  # Note: nested list\n",
    "\n",
    "oe = OrdinalEncoder(categories=categories)\n",
    "X_train['TCA_Tier_Encoded'] = oe.fit_transform(X_train[['TCA_Tier']])\n",
    "X_test['TCA_Tier_Encoded'] = oe.transform(X_test[['TCA_Tier']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode Level (degree) types\n",
    "level_dummies = pd.get_dummies(X_train['Level'], prefix='Level')\n",
    "X_train = pd.concat([X_train, level_dummies], axis=1)\n",
    "\n",
    "level_dummies_test = pd.get_dummies(X_test['Level'], prefix='Level')\n",
    "X_test = pd.concat([X_test, level_dummies_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Target Encoding due to high number of unique universities, cities, and countries\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "categorical_cols = ['City', 'University', 'Country', 'Program']\n",
    "encoder = TargetEncoder(cols=categorical_cols)\n",
    "\n",
    "# Fit on training data only\n",
    "X_train_encoded = encoder.fit_transform(X_train[categorical_cols], y_train)\n",
    "X_test_encoded = encoder.transform(X_test[categorical_cols])\n",
    "\n",
    "# Add encoded columns\n",
    "X_train = pd.concat([X_train, X_train_encoded], axis=1)\n",
    "X_test = pd.concat([X_test, X_test_encoded], axis=1)\n",
    "\n",
    "# Drop original categorical columns\n",
    "X_train = X_train.drop(categorical_cols, axis=1)\n",
    "X_test = X_test.drop(categorical_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop remaining categorical columns\n",
    "X_train = X_train.drop(columns=['Level', 'TCA_Tier'])\n",
    "X_test = X_test.drop(columns=['Level', 'TCA_Tier'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Scaling*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns to scale (exclude one-hot and ordinal encoded)\n",
    "cols_to_scale = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "cols_to_scale = cols_to_scale.drop(['TCA_Tier_Encoded'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train[cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])\n",
    "X_test[cols_to_scale] = scaler.transform(X_test[cols_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Models*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Support Vector Regressor': SVR(C=100, epsilon=0.1, kernel='linear', gamma='auto'),\n",
    "    'LightGBM Regressor ': LGBMRegressor(verbose=-1),\n",
    "    'XGBoost Regressor': XGBRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Mean Squared Error  R^2 Score\n",
      "Linear Regression               3.361692e+07   0.965518\n",
      "Random Forest                   6.157302e+06   0.993684\n",
      "Support Vector Regressor        4.595696e+07   0.952861\n",
      "LightGBM Regressor              7.967424e+06   0.991828\n",
      "XGBoost Regressor               4.416544e+06   0.995470\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate each model\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    \n",
    "    results[name] = {\n",
    "        'Mean Squared Error': mse,\n",
    "        'R^2 Score': r2\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SDS-CP026-env)",
   "language": "python",
   "name": "sds-cp026-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
